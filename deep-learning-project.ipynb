{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7844287,"sourceType":"datasetVersion","datasetId":4599218},{"sourceId":7844467,"sourceType":"datasetVersion","datasetId":4599353},{"sourceId":7852948,"sourceType":"datasetVersion","datasetId":4605645},{"sourceId":165894964,"sourceType":"kernelVersion"}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tqdm import tqdm\nimport torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\nimport matplotlib.pyplot as plt\nimport os\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:00:23.763824Z","iopub.execute_input":"2024-03-15T16:00:23.764203Z","iopub.status.idle":"2024-03-15T16:00:26.936449Z","shell.execute_reply.started":"2024-03-15T16:00:23.764174Z","shell.execute_reply":"2024-03-15T16:00:26.935541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Define the path to the data folder\ndata_dir = '/kaggle/input/small-project-dataset/extracted_images_small'\n\n# Define transformations to be applied to the images\ntransform = transforms.Compose([\n    transforms.Grayscale(),          # Convert images to grayscale\n    transforms.Resize((28, 28)),     # Resize images to 28x28\n    transforms.ToTensor(),           # Convert images to PyTorch tensors\n])\n\n# Create an ImageFolder dataset\ndataset = datasets.ImageFolder(root=data_dir, transform=transform)\n\n# Get the class labels\nclass_labels = dataset.classes\n\ntrain_size = int(0.6 * len(dataset))\ntest_size = int(0.2 * len(dataset))\neval_size = len(dataset) - train_size - test_size\n\n# Split the dataset into training, testing, and evaluation sets\ntrain_dataset, test_dataset, eval_dataset = random_split(dataset, [train_size, test_size, eval_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\neval_loader = DataLoader(eval_dataset, batch_size=64, shuffle=False)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:09:22.711842Z","iopub.execute_input":"2024-03-15T16:09:22.712727Z","iopub.status.idle":"2024-03-15T16:09:22.966771Z","shell.execute_reply.started":"2024-03-15T16:09:22.712689Z","shell.execute_reply":"2024-03-15T16:09:22.965696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:09:26.358147Z","iopub.execute_input":"2024-03-15T16:09:26.358562Z","iopub.status.idle":"2024-03-15T16:09:26.365776Z","shell.execute_reply.started":"2024-03-15T16:09:26.358530Z","shell.execute_reply":"2024-03-15T16:09:26.364697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col = int(len(class_labels)/8+1)\nfig, axes = plt.subplots(8, col,figsize=(15, 20))\n\nlabels = []\nfor image, class_index in tqdm(train_dataset, total=len(train_dataset)):\n    if class_index not in labels:\n        axes[class_index//col,class_index%col].imshow(image.permute(1, 2, 0))  # Convert tensor to image format (HWC)\n        axes[class_index//col,class_index%col].set_title(class_labels[class_index])\n        axes[class_index//col,class_index%col].axis('off')\n        labels.append(class_index)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:09:28.128593Z","iopub.execute_input":"2024-03-15T16:09:28.128970Z","iopub.status.idle":"2024-03-15T16:10:46.475707Z","shell.execute_reply.started":"2024-03-15T16:09:28.128940Z","shell.execute_reply":"2024-03-15T16:10:46.474651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass SymbolDetectorCNN(nn.Module):\n    def __init__(self):\n        \n        super(SymbolDetectorCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 30, 5)  # input channels, output channels, kernel size\n        self.pool = nn.MaxPool2d(2, 2)     # kernel size, stride\n        self.conv2 = nn.Conv2d(30, 15, 3)  # input channels, output channels, kernel size\n        self.fc1 = nn.Linear(15 * 5 * 5, 128)  # input size, output size\n        self.fc2 = nn.Linear(128, 82)  # input size, output size\n          # input size, output size\n        self.dropout = nn.Dropout(0.2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = self.dropout(x.view(-1, 15 * 5 * 5))  # flatten\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return F.softmax(x, dim=1)\n\n\n# Instantiate the CNN\nmodel = SymbolDetectorCNN()\n\n# Print the model architecture\nprint(model)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:10:59.556097Z","iopub.execute_input":"2024-03-15T16:10:59.557030Z","iopub.status.idle":"2024-03-15T16:10:59.570549Z","shell.execute_reply.started":"2024-03-15T16:10:59.556994Z","shell.execute_reply":"2024-03-15T16:10:59.569513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport matplotlib.pyplot as plt\n\n# Path to the folder containing images\nfolder_path = '/kaggle/input/equation-crohme-png/CROHME_training_png'\n\n# Iterate over the images in the folder\nfor i,filename in enumerate(os.listdir(folder_path)):\n    if filename.endswith('.png'):\n        # Load the image\n        image_path = os.path.join(folder_path, filename)\n        image = cv2.imread(image_path)\n\n        # Convert the image to grayscale\n        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n        # Apply thresholding to binarize the image\n        _, binary_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n\n        # Find contours in the binary image\n        contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        # Extract bounding boxes around the contours\n        character_boxes = []\n        for contour in contours:\n            x, y, w, h = cv2.boundingRect(contour)\n            # Filter out very small contours (noise)\n            if w > 10 and h > 10:\n                character_boxes.append((x, y, w, h))\n\n        # Draw bounding boxes on the original image\n        output_image = image.copy()\n        for (x, y, w, h) in character_boxes:\n            cv2.rectangle(output_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n\n        # Show the original image with bounding boxes\n        plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))\n        plt.axis('off')\n        plt.title(filename)  # Show filename as the title\n        plt.show()\n        \n        if(i>20):\n            break\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T17:05:15.277916Z","iopub.execute_input":"2024-03-15T17:05:15.278861Z","iopub.status.idle":"2024-03-15T17:05:19.052740Z","shell.execute_reply.started":"2024-03-15T17:05:15.278823Z","shell.execute_reply":"2024-03-15T17:05:19.051577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Path to the folder containing images\nfolder_path = '/kaggle/input/equation-crohme-png/CROHME_training_png'\n\n# Iterate over the images in the folder\nfor i,filename in enumerate(os.listdir(folder_path)):\n    if filename.endswith('.png'):\n        # Load the image\n        image_path = os.path.join(folder_path, filename)\n        image = cv2.imread(image_path)\n\n        # Convert the image to grayscale\n        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n        # Apply thresholding to binarize the image\n        _, binary_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n\n        # Compute horizontal projection (sum along rows)\n        horizontal_projection = np.sum(binary_image, axis=1)\n\n        # Compute vertical projection (sum along columns)\n        vertical_projection = np.sum(binary_image, axis=0)\n\n        # Plot horizontal projection\n        plt.figure(figsize=(12, 6))\n        plt.subplot(1, 3, 1)\n        plt.imshow(binary_image, cmap='gray')\n        plt.title('Binary Image')\n        plt.axis('off')\n\n        plt.subplot(1, 3, 2)\n        plt.plot(horizontal_projection, range(binary_image.shape[0]), color='black')\n        plt.title('Horizontal Projection')\n        plt.xlabel('Pixel Count')\n        plt.ylabel('Row')\n        plt.gca().invert_yaxis()  # Invert y-axis to match image coordinates\n\n        # Plot vertical projection\n        plt.subplot(1, 3, 3)\n        plt.plot(range(binary_image.shape[1]), vertical_projection, color='black')\n        plt.title('Vertical Projection')\n        plt.xlabel('Column')\n        plt.ylabel('Pixel Count')\n        \n        plt.suptitle(filename)  # Show filename as the title\n        plt.tight_layout()\n        plt.show()\n        \n        if i > 10:\n            break\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T17:07:26.646878Z","iopub.execute_input":"2024-03-15T17:07:26.647310Z","iopub.status.idle":"2024-03-15T17:07:34.956549Z","shell.execute_reply.started":"2024-03-15T17:07:26.647275Z","shell.execute_reply":"2024-03-15T17:07:34.955457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[0][1]","metadata":{"execution":{"iopub.status.busy":"2024-03-15T15:16:48.129962Z","iopub.execute_input":"2024-03-15T15:16:48.130339Z","iopub.status.idle":"2024-03-15T15:16:48.140125Z","shell.execute_reply.started":"2024-03-15T15:16:48.130312Z","shell.execute_reply":"2024-03-15T15:16:48.139105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = SymbolDetectorCNN()\nx.forward(dataset[0][0])","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:11:04.251447Z","iopub.execute_input":"2024-03-15T16:11:04.251827Z","iopub.status.idle":"2024-03-15T16:11:04.267360Z","shell.execute_reply.started":"2024-03-15T16:11:04.251795Z","shell.execute_reply":"2024-03-15T16:11:04.266355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = SymbolDetectorCNN().to(device)\n\n# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training loop\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    model.train()  # Set the model to training mode\n    running_loss = 0.0\n    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * images.size(0)\n    \n    epoch_loss = running_loss / len(train_loader.dataset)\n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n    \n    # Evaluation\n    model.eval()  # Set the model to evaluation mode\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = correct / total\n    print(f\"Test Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom tqdm import tqdm\n\n# Assuming train_loader and test_loader are defined\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = SymbolDetectorCNN().to(device)\n\n# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Learning rate scheduler\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n\n# Training loop\nnum_epochs = 100\nbest_accuracy = 0.0  # To track the best accuracy achieved during training\nfor epoch in range(num_epochs):\n    print(f\"Learning rate before epoch {epoch+1}: {optimizer.param_groups[0]['lr']}\")\n    model.train()  # Set the model to training mode\n    running_loss = 0.0\n    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * images.size(0)\n    \n    epoch_loss = running_loss / len(train_loader.dataset)\n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n    \n    # Evaluation\n    model.eval()  # Set the model to evaluation mode\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = correct / total\n    print(f\"Test Accuracy: {accuracy:.4f}\")\n    \n    # Adjust learning rate based on validation accuracy\n    scheduler.step(epoch_loss)\n    \n    # Save the model if it achieves the best accuracy so far\n    if accuracy > best_accuracy:\n        best_accuracy = accuracy\n        torch.save(model.state_dict(), 'best_model.pth')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:13:18.928066Z","iopub.execute_input":"2024-03-15T16:13:18.928581Z","iopub.status.idle":"2024-03-15T17:04:42.257193Z","shell.execute_reply.started":"2024-03-15T16:13:18.928548Z","shell.execute_reply":"2024-03-15T17:04:42.256147Z"},"trusted":true},"execution_count":null,"outputs":[]}]}